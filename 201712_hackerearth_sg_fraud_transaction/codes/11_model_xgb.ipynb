{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../inputs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unnecesary columns\n",
    "single_uniq_value_cols = ['cat_var_31', 'cat_var_35', 'cat_var_36', 'cat_var_37', 'cat_var_38', 'cat_var_40', 'cat_var_42']\n",
    "single_majority_value_cols = ['cat_var_23', 'cat_var_24', 'cat_var_25', 'cat_var_26',\\\n",
    "                              'cat_var_27', 'cat_var_28', 'cat_var_29', 'cat_var_30',\\\n",
    "                              'cat_var_32', 'cat_var_33', 'cat_var_34', 'cat_var_39',\\\n",
    "                              'cat_var_41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(single_uniq_value_cols, axis = 1, inplace = True)\n",
    "df.drop(single_majority_value_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna('NA', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id     object\n",
      "num_var_1         float64\n",
      "num_var_2         float64\n",
      "num_var_3         float64\n",
      "num_var_4         float64\n",
      "num_var_5         float64\n",
      "num_var_6         float64\n",
      "num_var_7         float64\n",
      "cat_var_1          object\n",
      "cat_var_2          object\n",
      "cat_var_3          object\n",
      "cat_var_4          object\n",
      "cat_var_5          object\n",
      "cat_var_6          object\n",
      "cat_var_7          object\n",
      "cat_var_8          object\n",
      "cat_var_9          object\n",
      "cat_var_10         object\n",
      "cat_var_11         object\n",
      "cat_var_12         object\n",
      "cat_var_13         object\n",
      "cat_var_14         object\n",
      "cat_var_15         object\n",
      "cat_var_16         object\n",
      "cat_var_17         object\n",
      "cat_var_18         object\n",
      "cat_var_19          int64\n",
      "cat_var_20          int64\n",
      "cat_var_21          int64\n",
      "cat_var_22          int64\n",
      "target              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num_var_1,  15184,  13385,  11273\n",
      " num_var_2,   5809,   5550,   5309\n",
      " num_var_3,     11,      8,      5\n",
      " num_var_4,   1061,   1006,    956\n",
      " num_var_5,   5321,   4622,   3737\n",
      " num_var_6,  13539,  11827,   9839\n",
      " num_var_7,  33188,  26213,  15224\n",
      " cat_var_1,    535,    535,    531\n",
      " cat_var_2,     62,     60,     59\n",
      " cat_var_3,    618,    617,    613\n",
      " cat_var_4,      2,      2,      2\n",
      " cat_var_5,      2,      2,      2\n",
      " cat_var_6,    516,    518,    515\n",
      " cat_var_7,     22,     20,     19\n",
      " cat_var_8,    464,    463,    460\n",
      " cat_var_9,      5,      5,      5\n",
      "cat_var_10,     23,     23,     23\n",
      "cat_var_11,      5,      5,      5\n",
      "cat_var_12,      5,      5,      5\n",
      "cat_var_13,     52,     52,     52\n",
      "cat_var_14,     12,     12,     12\n",
      "cat_var_15,      2,      2,      2\n",
      "cat_var_16,      2,      2,      2\n",
      "cat_var_17,      2,      2,      2\n",
      "cat_var_18,      2,      2,      2\n",
      "cat_var_19,      2,      2,      2\n",
      "cat_var_20,      2,      2,      2\n",
      "cat_var_21,      2,      2,      2\n",
      "cat_var_22,      2,      2,      2\n"
     ]
    }
   ],
   "source": [
    "# check how many columns are common between train and test\n",
    "col_list = df_submit.columns.tolist()\n",
    "col_list.remove('transaction_id')\n",
    "for col in col_list:\n",
    "    common_len = len(pd.merge(left = pd.DataFrame(df_submit[col].unique(), columns = [col]), \\\n",
    "                                                  right = pd.DataFrame(df[col].unique(), columns = [col]),\\\n",
    "                                                  how = 'inner', on = col))\n",
    "    print (('%10s, %6d, %6d, %6d') % (col, len(df_submit[col].unique()), len(df[col].unique()), common_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols_xgb_encode = df.dtypes[~df.dtypes.isin([np.int64, np.float64])].index.tolist()\n",
    "# print (input_cols_xgb_encode)\n",
    "input_cols_xgb_encode.remove('transaction_id')\n",
    "input_cols_xgb_numeric = df.dtypes[df.dtypes.isin([np.int64, np.float64])].index.tolist()\n",
    "input_cols_xgb_numeric.remove('target')\n",
    "target_cols_xgb = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_var_1\n",
      "cat_var_2\n",
      "cat_var_3\n",
      "cat_var_4\n",
      "cat_var_5\n",
      "cat_var_6\n",
      "cat_var_7\n",
      "cat_var_8\n",
      "cat_var_9\n",
      "cat_var_10\n",
      "cat_var_11\n",
      "cat_var_12\n",
      "cat_var_13\n",
      "cat_var_14\n",
      "cat_var_15\n",
      "cat_var_16\n",
      "cat_var_17\n",
      "cat_var_18\n"
     ]
    }
   ],
   "source": [
    "X_xgb = df[input_cols_xgb_encode + input_cols_xgb_numeric].as_matrix()\n",
    "label_enc = [LabelEncoder() for i in range(len(input_cols_xgb_encode))]\n",
    "\n",
    "for i in range(len(label_enc)):\n",
    "    print (input_cols_xgb_encode[i])\n",
    "    label_enc[i].fit(X_xgb[:, i])\n",
    "    X_xgb[:, i] = label_enc[i].transform(X_xgb[:, i])\n",
    "\n",
    "y_xgb = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do stratified splitting as training time is too large otherwise\n",
    "X_xgb_train, X_xgb_test, y_xgb_train, y_xgb_test = train_test_split(X_xgb, y_xgb, test_size = 0.4, \\\n",
    "                                                                    stratify = y_xgb, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# get the optimum no of trees for learning rate of 0.1\n",
    "parameters = {'n_estimators' : [10, 50, 100]}\n",
    "xgb_clf = XGBClassifier(random_state=42, n_jobs = -1,learning_rate = 0.3)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.719150</td>\n",
       "      <td>0.092863</td>\n",
       "      <td>0.718395</td>\n",
       "      <td>0.719305</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719752</td>\n",
       "      <td>0.718115</td>\n",
       "      <td>0.715884</td>\n",
       "      <td>0.719682</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.719631</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.663242</td>\n",
       "      <td>0.136580</td>\n",
       "      <td>0.724462</td>\n",
       "      <td>0.733839</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.726164</td>\n",
       "      <td>0.732198</td>\n",
       "      <td>0.726878</td>\n",
       "      <td>0.733261</td>\n",
       "      <td>0.721304</td>\n",
       "      <td>0.734780</td>\n",
       "      <td>0.723503</td>\n",
       "      <td>0.735118</td>\n",
       "      <td>0.240348</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.405108</td>\n",
       "      <td>0.266954</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.745599</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728943</td>\n",
       "      <td>0.743185</td>\n",
       "      <td>0.727138</td>\n",
       "      <td>0.745282</td>\n",
       "      <td>0.722644</td>\n",
       "      <td>0.746589</td>\n",
       "      <td>0.721025</td>\n",
       "      <td>0.747341</td>\n",
       "      <td>1.835164</td>\n",
       "      <td>0.069440</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.719150         0.092863         0.718395          0.719305   \n",
       "1       6.663242         0.136580         0.724462          0.733839   \n",
       "2      15.405108         0.266954         0.724937          0.745599   \n",
       "\n",
       "  param_n_estimators                 params  rank_test_score  \\\n",
       "0                 10   {'n_estimators': 10}                3   \n",
       "1                 50   {'n_estimators': 50}                2   \n",
       "2                100  {'n_estimators': 100}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.719194            0.719794           0.719752   \n",
       "1           0.726164            0.732198           0.726878   \n",
       "2           0.728943            0.743185           0.727138   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.718115           0.715884            0.719682   \n",
       "1            0.733261           0.721304            0.734780   \n",
       "2            0.745282           0.722644            0.746589   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.718750            0.719631      0.015807        0.001200   \n",
       "1           0.723503            0.735118      0.240348        0.002321   \n",
       "2           0.721025            0.747341      1.835164        0.069440   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.001492         0.000690  \n",
       "1        0.002215         0.001178  \n",
       "2        0.003219         0.001576  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# now tune the max_depth and min_child_weight\n",
    "parameters = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42, learning_rate = 0.3, n_estimators = 100)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.359841</td>\n",
       "      <td>0.311620</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.745599</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_child_weight': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728943</td>\n",
       "      <td>0.743185</td>\n",
       "      <td>0.727138</td>\n",
       "      <td>0.745282</td>\n",
       "      <td>0.722644</td>\n",
       "      <td>0.746589</td>\n",
       "      <td>0.721025</td>\n",
       "      <td>0.747341</td>\n",
       "      <td>1.734450</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.916319</td>\n",
       "      <td>0.196086</td>\n",
       "      <td>0.725855</td>\n",
       "      <td>0.746815</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_child_weight': 3}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>0.728371</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.724328</td>\n",
       "      <td>0.747624</td>\n",
       "      <td>0.720214</td>\n",
       "      <td>0.747220</td>\n",
       "      <td>0.874035</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.357609</td>\n",
       "      <td>0.194765</td>\n",
       "      <td>0.724889</td>\n",
       "      <td>0.747230</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_child_weight': 5}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.728444</td>\n",
       "      <td>0.745653</td>\n",
       "      <td>0.727379</td>\n",
       "      <td>0.746878</td>\n",
       "      <td>0.722380</td>\n",
       "      <td>0.748244</td>\n",
       "      <td>0.721352</td>\n",
       "      <td>0.748146</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.994885</td>\n",
       "      <td>0.330006</td>\n",
       "      <td>0.725286</td>\n",
       "      <td>0.797818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_child_weight': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.730341</td>\n",
       "      <td>0.793130</td>\n",
       "      <td>0.725124</td>\n",
       "      <td>0.798998</td>\n",
       "      <td>0.724580</td>\n",
       "      <td>0.802828</td>\n",
       "      <td>0.721101</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>1.450363</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.070078</td>\n",
       "      <td>0.316349</td>\n",
       "      <td>0.725624</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 5, 'min_child_weight': 3}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.729511</td>\n",
       "      <td>0.793546</td>\n",
       "      <td>0.726839</td>\n",
       "      <td>0.792004</td>\n",
       "      <td>0.723877</td>\n",
       "      <td>0.802254</td>\n",
       "      <td>0.722269</td>\n",
       "      <td>0.799495</td>\n",
       "      <td>0.348643</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.004201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.229631</td>\n",
       "      <td>0.324401</td>\n",
       "      <td>0.725851</td>\n",
       "      <td>0.794581</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_child_weight': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.730880</td>\n",
       "      <td>0.792719</td>\n",
       "      <td>0.727261</td>\n",
       "      <td>0.789829</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.797038</td>\n",
       "      <td>0.721062</td>\n",
       "      <td>0.798737</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.519854</td>\n",
       "      <td>0.465707</td>\n",
       "      <td>0.726367</td>\n",
       "      <td>0.862441</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 7, 'min_child_weight': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731673</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>0.726544</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.722059</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.725192</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.296082</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.247919</td>\n",
       "      <td>0.452995</td>\n",
       "      <td>0.724829</td>\n",
       "      <td>0.851764</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 7, 'min_child_weight': 3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.728593</td>\n",
       "      <td>0.851682</td>\n",
       "      <td>0.724043</td>\n",
       "      <td>0.853082</td>\n",
       "      <td>0.722027</td>\n",
       "      <td>0.850947</td>\n",
       "      <td>0.724655</td>\n",
       "      <td>0.851346</td>\n",
       "      <td>0.428996</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.747664</td>\n",
       "      <td>0.411032</td>\n",
       "      <td>0.724326</td>\n",
       "      <td>0.847090</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 7, 'min_child_weight': 5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.730793</td>\n",
       "      <td>0.845526</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>0.849775</td>\n",
       "      <td>0.723891</td>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.717819</td>\n",
       "      <td>0.848041</td>\n",
       "      <td>0.315663</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.822519</td>\n",
       "      <td>0.501242</td>\n",
       "      <td>0.724222</td>\n",
       "      <td>0.917474</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 9, 'min_child_weight': 1}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.728286</td>\n",
       "      <td>0.917099</td>\n",
       "      <td>0.724349</td>\n",
       "      <td>0.920809</td>\n",
       "      <td>0.720412</td>\n",
       "      <td>0.918904</td>\n",
       "      <td>0.723840</td>\n",
       "      <td>0.913083</td>\n",
       "      <td>0.326213</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.503719</td>\n",
       "      <td>0.499926</td>\n",
       "      <td>0.723908</td>\n",
       "      <td>0.895176</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 9, 'min_child_weight': 3}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>0.723402</td>\n",
       "      <td>0.899316</td>\n",
       "      <td>0.717851</td>\n",
       "      <td>0.891692</td>\n",
       "      <td>0.724833</td>\n",
       "      <td>0.893085</td>\n",
       "      <td>4.615148</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.002988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.179524</td>\n",
       "      <td>0.509158</td>\n",
       "      <td>0.723510</td>\n",
       "      <td>0.890445</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 9, 'min_child_weight': 5}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.728551</td>\n",
       "      <td>0.887175</td>\n",
       "      <td>0.722503</td>\n",
       "      <td>0.893391</td>\n",
       "      <td>0.720506</td>\n",
       "      <td>0.890683</td>\n",
       "      <td>0.722481</td>\n",
       "      <td>0.890529</td>\n",
       "      <td>3.706505</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.002204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       20.359841         0.311620         0.724937          0.745599   \n",
       "1       12.916319         0.196086         0.725855          0.746815   \n",
       "2       12.357609         0.194765         0.724889          0.747230   \n",
       "3       21.994885         0.330006         0.725286          0.797818   \n",
       "4       23.070078         0.316349         0.725624          0.796825   \n",
       "5       23.229631         0.324401         0.725851          0.794581   \n",
       "6       32.519854         0.465707         0.726367          0.862441   \n",
       "7       32.247919         0.452995         0.724829          0.851764   \n",
       "8       31.747664         0.411032         0.724326          0.847090   \n",
       "9       35.822519         0.501242         0.724222          0.917474   \n",
       "10      39.503719         0.499926         0.723908          0.895176   \n",
       "11      41.179524         0.509158         0.723510          0.890445   \n",
       "\n",
       "   param_max_depth param_min_child_weight  \\\n",
       "0                3                      1   \n",
       "1                3                      3   \n",
       "2                3                      5   \n",
       "3                5                      1   \n",
       "4                5                      3   \n",
       "5                5                      5   \n",
       "6                7                      1   \n",
       "7                7                      3   \n",
       "8                7                      5   \n",
       "9                9                      1   \n",
       "10               9                      3   \n",
       "11               9                      5   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "0   {'max_depth': 3, 'min_child_weight': 1}                6   \n",
       "1   {'max_depth': 3, 'min_child_weight': 3}                2   \n",
       "2   {'max_depth': 3, 'min_child_weight': 5}                7   \n",
       "3   {'max_depth': 5, 'min_child_weight': 1}                5   \n",
       "4   {'max_depth': 5, 'min_child_weight': 3}                4   \n",
       "5   {'max_depth': 5, 'min_child_weight': 5}                3   \n",
       "6   {'max_depth': 7, 'min_child_weight': 1}                1   \n",
       "7   {'max_depth': 7, 'min_child_weight': 3}                8   \n",
       "8   {'max_depth': 7, 'min_child_weight': 5}                9   \n",
       "9   {'max_depth': 9, 'min_child_weight': 1}               10   \n",
       "10  {'max_depth': 9, 'min_child_weight': 3}               11   \n",
       "11  {'max_depth': 9, 'min_child_weight': 5}               12   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.728943            0.743185           0.727138   \n",
       "1            0.730507            0.745117           0.728371   \n",
       "2            0.728444            0.745653           0.727379   \n",
       "3            0.730341            0.793130           0.725124   \n",
       "4            0.729511            0.793546           0.726839   \n",
       "5            0.730880            0.792719           0.727261   \n",
       "6            0.731673            0.860613           0.726544   \n",
       "7            0.728593            0.851682           0.724043   \n",
       "8            0.730793            0.845526           0.724800   \n",
       "9            0.728286            0.917099           0.724349   \n",
       "10           0.729545            0.896612           0.723402   \n",
       "11           0.728551            0.887175           0.722503   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0             0.745282           0.722644            0.746589   \n",
       "1             0.747300           0.724328            0.747624   \n",
       "2             0.746878           0.722380            0.748244   \n",
       "3             0.798998           0.724580            0.802828   \n",
       "4             0.792004           0.723877            0.802254   \n",
       "5             0.789829           0.724200            0.797038   \n",
       "6             0.865417           0.722059            0.860335   \n",
       "7             0.853082           0.722027            0.850947   \n",
       "8             0.849775           0.723891            0.845018   \n",
       "9             0.920809           0.720412            0.918904   \n",
       "10            0.899316           0.717851            0.891692   \n",
       "11            0.893391           0.720506            0.890683   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.721025            0.747341      1.734450        0.010527   \n",
       "1            0.720214            0.747220      0.874035        0.008006   \n",
       "2            0.721352            0.748146      0.064920        0.003446   \n",
       "3            0.721101            0.796317      1.450363        0.032703   \n",
       "4            0.722269            0.799495      0.348643        0.008378   \n",
       "5            0.721062            0.798737      0.272008        0.020730   \n",
       "6            0.725192            0.863398      0.296082        0.024179   \n",
       "7            0.724655            0.851346      0.428996        0.026462   \n",
       "8            0.717819            0.848041      0.315663        0.008574   \n",
       "9            0.723840            0.913083      0.326213        0.010233   \n",
       "10           0.724833            0.893085      4.615148        0.007512   \n",
       "11           0.722481            0.890529      3.706505        0.024015   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.003219         0.001576  \n",
       "1         0.003941         0.000992  \n",
       "2         0.003067         0.001058  \n",
       "3         0.003301         0.003561  \n",
       "4         0.002779         0.004201  \n",
       "5         0.003638         0.003513  \n",
       "6         0.003469         0.002095  \n",
       "7         0.002380         0.000804  \n",
       "8         0.004598         0.001927  \n",
       "9         0.002793         0.002854  \n",
       "10        0.004171         0.002988  \n",
       "11        0.003021         0.002204  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# now tune gamma\n",
    "parameters = {\n",
    " 'gamma':[x/10.0 for x in range(0, 6)]\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42, learning_rate = 0.3, n_estimators = 100,\\\n",
    "                        max_depth = 7, min_child_weight = 1, n_jobs = -1)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.861532</td>\n",
       "      <td>0.481146</td>\n",
       "      <td>0.726367</td>\n",
       "      <td>0.862441</td>\n",
       "      <td>0</td>\n",
       "      <td>{'gamma': 0.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731673</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>0.726544</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.722059</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.725192</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>1.720997</td>\n",
       "      <td>0.085661</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.803550</td>\n",
       "      <td>0.422498</td>\n",
       "      <td>0.725340</td>\n",
       "      <td>0.861758</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gamma': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.860676</td>\n",
       "      <td>0.725719</td>\n",
       "      <td>0.862302</td>\n",
       "      <td>0.722840</td>\n",
       "      <td>0.866240</td>\n",
       "      <td>0.723035</td>\n",
       "      <td>0.857815</td>\n",
       "      <td>1.138195</td>\n",
       "      <td>0.029852</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.128219</td>\n",
       "      <td>0.414794</td>\n",
       "      <td>0.724744</td>\n",
       "      <td>0.861673</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'gamma': 0.2}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.729036</td>\n",
       "      <td>0.860953</td>\n",
       "      <td>0.726862</td>\n",
       "      <td>0.866847</td>\n",
       "      <td>0.721179</td>\n",
       "      <td>0.862586</td>\n",
       "      <td>0.721898</td>\n",
       "      <td>0.856308</td>\n",
       "      <td>1.320895</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.789602</td>\n",
       "      <td>0.456254</td>\n",
       "      <td>0.724025</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'gamma': 0.3}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>0.860024</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.856584</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>0.858772</td>\n",
       "      <td>0.721486</td>\n",
       "      <td>0.858904</td>\n",
       "      <td>2.542959</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.959458</td>\n",
       "      <td>0.425751</td>\n",
       "      <td>0.724383</td>\n",
       "      <td>0.861805</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'gamma': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.730299</td>\n",
       "      <td>0.864796</td>\n",
       "      <td>0.722398</td>\n",
       "      <td>0.858763</td>\n",
       "      <td>0.720548</td>\n",
       "      <td>0.863083</td>\n",
       "      <td>0.724287</td>\n",
       "      <td>0.860576</td>\n",
       "      <td>2.068837</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.217243</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.725399</td>\n",
       "      <td>0.861777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.860646</td>\n",
       "      <td>0.726453</td>\n",
       "      <td>0.858949</td>\n",
       "      <td>0.723917</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>0.723952</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>2.687178</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      32.861532         0.481146         0.726367          0.862441   \n",
       "1      31.803550         0.422498         0.725340          0.861758   \n",
       "2      33.128219         0.414794         0.724744          0.861673   \n",
       "3      32.789602         0.456254         0.724025          0.858571   \n",
       "4      32.959458         0.425751         0.724383          0.861805   \n",
       "5      34.217243         0.451944         0.725399          0.861777   \n",
       "\n",
       "  param_gamma          params  rank_test_score  split0_test_score  \\\n",
       "0           0  {'gamma': 0.0}                1           0.731673   \n",
       "1         0.1  {'gamma': 0.1}                3           0.729765   \n",
       "2         0.2  {'gamma': 0.2}                4           0.729036   \n",
       "3         0.3  {'gamma': 0.3}                6           0.731211   \n",
       "4         0.4  {'gamma': 0.4}                5           0.730299   \n",
       "5         0.5  {'gamma': 0.5}                2           0.727275   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.860613           0.726544            0.865417   \n",
       "1            0.860676           0.725719            0.862302   \n",
       "2            0.860953           0.726862            0.866847   \n",
       "3            0.860024           0.723478            0.856584   \n",
       "4            0.864796           0.722398            0.858763   \n",
       "5            0.860646           0.726453            0.858949   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.722059            0.860335           0.725192   \n",
       "1           0.722840            0.866240           0.723035   \n",
       "2           0.721179            0.862586           0.721898   \n",
       "3           0.719924            0.858772           0.721486   \n",
       "4           0.720548            0.863083           0.724287   \n",
       "5           0.723917            0.863699           0.723952   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.863398      1.720997        0.085661        0.003469   \n",
       "1            0.857815      1.138195        0.029852        0.002797   \n",
       "2            0.856308      1.320895        0.013766        0.003306   \n",
       "3            0.858904      2.542959        0.069028        0.004336   \n",
       "4            0.860576      2.068837        0.019188        0.003663   \n",
       "5            0.863814      2.687178        0.042169        0.001493   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.002095  \n",
       "1         0.003046  \n",
       "2         0.003772  \n",
       "3         0.001246  \n",
       "4         0.002310  \n",
       "5         0.002069  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# now tune subsample and column sample\n",
    "parameters = {\n",
    " 'subsample':[x/10.0 for x in range(6,11)],\n",
    " 'colsample_bytree':[x/10.0 for x in range(6,11)]\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42, learning_rate = 0.3, n_estimators = 100,\\\n",
    "                        max_depth = 7, min_child_weight = 1, n_jobs = -1,\\\n",
    "                        gamma = 0)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.907971</td>\n",
       "      <td>0.468410</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.850650</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'subsample': 0.6}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.728044</td>\n",
       "      <td>0.848520</td>\n",
       "      <td>0.723493</td>\n",
       "      <td>0.853176</td>\n",
       "      <td>0.723247</td>\n",
       "      <td>0.849355</td>\n",
       "      <td>0.722868</td>\n",
       "      <td>0.851548</td>\n",
       "      <td>1.194023</td>\n",
       "      <td>0.096704</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.605926</td>\n",
       "      <td>0.446301</td>\n",
       "      <td>0.725267</td>\n",
       "      <td>0.857550</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'subsample': 0.7}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.728432</td>\n",
       "      <td>0.857340</td>\n",
       "      <td>0.724025</td>\n",
       "      <td>0.859603</td>\n",
       "      <td>0.726137</td>\n",
       "      <td>0.856198</td>\n",
       "      <td>0.722476</td>\n",
       "      <td>0.857057</td>\n",
       "      <td>1.423763</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.228731</td>\n",
       "      <td>0.505184</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>0.856750</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'subsample': 0.8}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.730111</td>\n",
       "      <td>0.850516</td>\n",
       "      <td>0.725108</td>\n",
       "      <td>0.859639</td>\n",
       "      <td>0.722847</td>\n",
       "      <td>0.858763</td>\n",
       "      <td>0.722085</td>\n",
       "      <td>0.858084</td>\n",
       "      <td>1.251284</td>\n",
       "      <td>0.063795</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.532653</td>\n",
       "      <td>0.431327</td>\n",
       "      <td>0.724171</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'subsample': 0.9}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.725092</td>\n",
       "      <td>0.856241</td>\n",
       "      <td>0.726358</td>\n",
       "      <td>0.859014</td>\n",
       "      <td>0.721512</td>\n",
       "      <td>0.858922</td>\n",
       "      <td>0.723724</td>\n",
       "      <td>0.860359</td>\n",
       "      <td>1.544426</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.501383</td>\n",
       "      <td>0.393119</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.847904</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'subsample': 1.0}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.732711</td>\n",
       "      <td>0.845170</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.851675</td>\n",
       "      <td>0.722813</td>\n",
       "      <td>0.851245</td>\n",
       "      <td>0.721868</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>0.220653</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.003606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.388328</td>\n",
       "      <td>0.444355</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>0.854196</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'subsample': 0.6}</td>\n",
       "      <td>21</td>\n",
       "      <td>0.726743</td>\n",
       "      <td>0.850237</td>\n",
       "      <td>0.724678</td>\n",
       "      <td>0.856413</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>0.854424</td>\n",
       "      <td>0.723206</td>\n",
       "      <td>0.855710</td>\n",
       "      <td>0.350804</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.746616</td>\n",
       "      <td>0.482816</td>\n",
       "      <td>0.724641</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'subsample': 0.7}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.730176</td>\n",
       "      <td>0.858808</td>\n",
       "      <td>0.723253</td>\n",
       "      <td>0.864128</td>\n",
       "      <td>0.720318</td>\n",
       "      <td>0.861290</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>1.761759</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.729116</td>\n",
       "      <td>0.465885</td>\n",
       "      <td>0.724464</td>\n",
       "      <td>0.859971</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'subsample': 0.8}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.727309</td>\n",
       "      <td>0.857096</td>\n",
       "      <td>0.724803</td>\n",
       "      <td>0.861125</td>\n",
       "      <td>0.724414</td>\n",
       "      <td>0.862890</td>\n",
       "      <td>0.721331</td>\n",
       "      <td>0.858772</td>\n",
       "      <td>0.262298</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.002211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.150066</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>0.725674</td>\n",
       "      <td>0.859126</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'subsample': 0.9}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.728450</td>\n",
       "      <td>0.860483</td>\n",
       "      <td>0.723956</td>\n",
       "      <td>0.851510</td>\n",
       "      <td>0.721404</td>\n",
       "      <td>0.862825</td>\n",
       "      <td>0.728885</td>\n",
       "      <td>0.861686</td>\n",
       "      <td>0.162329</td>\n",
       "      <td>0.024495</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.283763</td>\n",
       "      <td>0.442084</td>\n",
       "      <td>0.725945</td>\n",
       "      <td>0.855768</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'subsample': 1.0}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.728624</td>\n",
       "      <td>0.854176</td>\n",
       "      <td>0.728416</td>\n",
       "      <td>0.857433</td>\n",
       "      <td>0.724867</td>\n",
       "      <td>0.854914</td>\n",
       "      <td>0.721875</td>\n",
       "      <td>0.856548</td>\n",
       "      <td>1.358577</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48.689970</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.723970</td>\n",
       "      <td>0.857702</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'subsample': 0.6}</td>\n",
       "      <td>18</td>\n",
       "      <td>0.727337</td>\n",
       "      <td>0.855048</td>\n",
       "      <td>0.725502</td>\n",
       "      <td>0.858190</td>\n",
       "      <td>0.722904</td>\n",
       "      <td>0.857257</td>\n",
       "      <td>0.720135</td>\n",
       "      <td>0.860314</td>\n",
       "      <td>5.329143</td>\n",
       "      <td>0.075669</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.298949</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.723060</td>\n",
       "      <td>0.864072</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'subsample': 0.7}</td>\n",
       "      <td>23</td>\n",
       "      <td>0.724593</td>\n",
       "      <td>0.861012</td>\n",
       "      <td>0.720841</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>0.722251</td>\n",
       "      <td>0.865415</td>\n",
       "      <td>0.724555</td>\n",
       "      <td>0.865565</td>\n",
       "      <td>1.627084</td>\n",
       "      <td>0.090704</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31.991102</td>\n",
       "      <td>0.507023</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>0.866521</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'subsample': 0.8}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728976</td>\n",
       "      <td>0.867665</td>\n",
       "      <td>0.723487</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.723330</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.726191</td>\n",
       "      <td>0.869143</td>\n",
       "      <td>1.032818</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.811134</td>\n",
       "      <td>0.483458</td>\n",
       "      <td>0.726831</td>\n",
       "      <td>0.866668</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'subsample': 0.9}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730161</td>\n",
       "      <td>0.862143</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>0.870823</td>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.724471</td>\n",
       "      <td>0.863887</td>\n",
       "      <td>2.715784</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27.081200</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>0.724685</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'subsample': 1.0}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.728445</td>\n",
       "      <td>0.859497</td>\n",
       "      <td>0.723611</td>\n",
       "      <td>0.855728</td>\n",
       "      <td>0.722506</td>\n",
       "      <td>0.859698</td>\n",
       "      <td>0.724179</td>\n",
       "      <td>0.853700</td>\n",
       "      <td>0.293655</td>\n",
       "      <td>0.016950</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.002546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48.692760</td>\n",
       "      <td>0.555488</td>\n",
       "      <td>0.722708</td>\n",
       "      <td>0.861894</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'subsample': 0.6}</td>\n",
       "      <td>24</td>\n",
       "      <td>0.722531</td>\n",
       "      <td>0.862634</td>\n",
       "      <td>0.723767</td>\n",
       "      <td>0.858155</td>\n",
       "      <td>0.719495</td>\n",
       "      <td>0.862640</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>0.864149</td>\n",
       "      <td>6.159865</td>\n",
       "      <td>0.081660</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60.150500</td>\n",
       "      <td>0.645008</td>\n",
       "      <td>0.723083</td>\n",
       "      <td>0.866905</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'subsample': 0.7}</td>\n",
       "      <td>22</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.721203</td>\n",
       "      <td>0.866742</td>\n",
       "      <td>0.721993</td>\n",
       "      <td>0.866260</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>0.864796</td>\n",
       "      <td>0.184696</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.001829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55.692871</td>\n",
       "      <td>0.621210</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'subsample': 0.8}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.728964</td>\n",
       "      <td>0.872582</td>\n",
       "      <td>0.724543</td>\n",
       "      <td>0.870777</td>\n",
       "      <td>0.721044</td>\n",
       "      <td>0.869603</td>\n",
       "      <td>0.723511</td>\n",
       "      <td>0.867261</td>\n",
       "      <td>0.649004</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.001931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37.206800</td>\n",
       "      <td>0.450937</td>\n",
       "      <td>0.723945</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'subsample': 0.9}</td>\n",
       "      <td>19</td>\n",
       "      <td>0.732686</td>\n",
       "      <td>0.870549</td>\n",
       "      <td>0.722363</td>\n",
       "      <td>0.866344</td>\n",
       "      <td>0.719063</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>0.721666</td>\n",
       "      <td>0.870186</td>\n",
       "      <td>7.069506</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.582893</td>\n",
       "      <td>0.462278</td>\n",
       "      <td>0.724416</td>\n",
       "      <td>0.861577</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'subsample': 1.0}</td>\n",
       "      <td>14</td>\n",
       "      <td>0.730269</td>\n",
       "      <td>0.860869</td>\n",
       "      <td>0.723964</td>\n",
       "      <td>0.865487</td>\n",
       "      <td>0.718622</td>\n",
       "      <td>0.861403</td>\n",
       "      <td>0.724808</td>\n",
       "      <td>0.858550</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.002499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47.498314</td>\n",
       "      <td>0.495538</td>\n",
       "      <td>0.722645</td>\n",
       "      <td>0.861662</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'subsample': 0.6}</td>\n",
       "      <td>25</td>\n",
       "      <td>0.727150</td>\n",
       "      <td>0.860404</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>0.717228</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.722086</td>\n",
       "      <td>0.864453</td>\n",
       "      <td>0.432748</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44.359951</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.723801</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'subsample': 0.7}</td>\n",
       "      <td>20</td>\n",
       "      <td>0.728015</td>\n",
       "      <td>0.868499</td>\n",
       "      <td>0.725753</td>\n",
       "      <td>0.866013</td>\n",
       "      <td>0.719965</td>\n",
       "      <td>0.868262</td>\n",
       "      <td>0.721471</td>\n",
       "      <td>0.866922</td>\n",
       "      <td>0.302666</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40.536646</td>\n",
       "      <td>0.464841</td>\n",
       "      <td>0.724829</td>\n",
       "      <td>0.869346</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'subsample': 0.8}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.730922</td>\n",
       "      <td>0.865706</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.872601</td>\n",
       "      <td>0.720351</td>\n",
       "      <td>0.870552</td>\n",
       "      <td>0.725197</td>\n",
       "      <td>0.868526</td>\n",
       "      <td>0.328412</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>37.972121</td>\n",
       "      <td>0.447837</td>\n",
       "      <td>0.724365</td>\n",
       "      <td>0.869435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'subsample': 0.9}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.728726</td>\n",
       "      <td>0.870146</td>\n",
       "      <td>0.725989</td>\n",
       "      <td>0.870597</td>\n",
       "      <td>0.720358</td>\n",
       "      <td>0.868067</td>\n",
       "      <td>0.722387</td>\n",
       "      <td>0.868929</td>\n",
       "      <td>3.308217</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31.509660</td>\n",
       "      <td>0.440297</td>\n",
       "      <td>0.726367</td>\n",
       "      <td>0.862441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1.0, 'subsample': 1.0}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731673</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>0.726544</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.722059</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.725192</td>\n",
       "      <td>0.863398</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       29.907971         0.468410         0.724413          0.850650   \n",
       "1       27.605926         0.446301         0.725267          0.857550   \n",
       "2       27.228731         0.505184         0.725038          0.856750   \n",
       "3       22.532653         0.431327         0.724171          0.858634   \n",
       "4       18.501383         0.393119         0.726200          0.847904   \n",
       "5       31.388328         0.444355         0.723183          0.854196   \n",
       "6       31.746616         0.482816         0.724641          0.860360   \n",
       "7       29.729116         0.465885         0.724464          0.859971   \n",
       "8       27.150066         0.456159         0.725674          0.859126   \n",
       "9       25.283763         0.442084         0.725945          0.855768   \n",
       "10      48.689970         0.522679         0.723970          0.857702   \n",
       "11      35.298949         0.480709         0.723060          0.864072   \n",
       "12      31.991102         0.507023         0.725496          0.866521   \n",
       "13      29.811134         0.483458         0.726831          0.866668   \n",
       "14      27.081200         0.455951         0.724685          0.857156   \n",
       "15      48.692760         0.555488         0.722708          0.861894   \n",
       "16      60.150500         0.645008         0.723083          0.866905   \n",
       "17      55.692871         0.621210         0.724516          0.870056   \n",
       "18      37.206800         0.450937         0.723945          0.869489   \n",
       "19      29.582893         0.462278         0.724416          0.861577   \n",
       "20      47.498314         0.495538         0.722645          0.861662   \n",
       "21      44.359951         0.476640         0.723801          0.867424   \n",
       "22      40.536646         0.464841         0.724829          0.869346   \n",
       "23      37.972121         0.447837         0.724365          0.869435   \n",
       "24      31.509660         0.440297         0.726367          0.862441   \n",
       "\n",
       "   param_colsample_bytree param_subsample  \\\n",
       "0                     0.6             0.6   \n",
       "1                     0.6             0.7   \n",
       "2                     0.6             0.8   \n",
       "3                     0.6             0.9   \n",
       "4                     0.6               1   \n",
       "5                     0.7             0.6   \n",
       "6                     0.7             0.7   \n",
       "7                     0.7             0.8   \n",
       "8                     0.7             0.9   \n",
       "9                     0.7               1   \n",
       "10                    0.8             0.6   \n",
       "11                    0.8             0.7   \n",
       "12                    0.8             0.8   \n",
       "13                    0.8             0.9   \n",
       "14                    0.8               1   \n",
       "15                    0.9             0.6   \n",
       "16                    0.9             0.7   \n",
       "17                    0.9             0.8   \n",
       "18                    0.9             0.9   \n",
       "19                    0.9               1   \n",
       "20                      1             0.6   \n",
       "21                      1             0.7   \n",
       "22                      1             0.8   \n",
       "23                      1             0.9   \n",
       "24                      1               1   \n",
       "\n",
       "                                         params  rank_test_score  \\\n",
       "0   {'colsample_bytree': 0.6, 'subsample': 0.6}               15   \n",
       "1   {'colsample_bytree': 0.6, 'subsample': 0.7}                7   \n",
       "2   {'colsample_bytree': 0.6, 'subsample': 0.8}                8   \n",
       "3   {'colsample_bytree': 0.6, 'subsample': 0.9}               17   \n",
       "4   {'colsample_bytree': 0.6, 'subsample': 1.0}                3   \n",
       "5   {'colsample_bytree': 0.7, 'subsample': 0.6}               21   \n",
       "6   {'colsample_bytree': 0.7, 'subsample': 0.7}               11   \n",
       "7   {'colsample_bytree': 0.7, 'subsample': 0.8}               13   \n",
       "8   {'colsample_bytree': 0.7, 'subsample': 0.9}                5   \n",
       "9   {'colsample_bytree': 0.7, 'subsample': 1.0}                4   \n",
       "10  {'colsample_bytree': 0.8, 'subsample': 0.6}               18   \n",
       "11  {'colsample_bytree': 0.8, 'subsample': 0.7}               23   \n",
       "12  {'colsample_bytree': 0.8, 'subsample': 0.8}                6   \n",
       "13  {'colsample_bytree': 0.8, 'subsample': 0.9}                1   \n",
       "14  {'colsample_bytree': 0.8, 'subsample': 1.0}               10   \n",
       "15  {'colsample_bytree': 0.9, 'subsample': 0.6}               24   \n",
       "16  {'colsample_bytree': 0.9, 'subsample': 0.7}               22   \n",
       "17  {'colsample_bytree': 0.9, 'subsample': 0.8}               12   \n",
       "18  {'colsample_bytree': 0.9, 'subsample': 0.9}               19   \n",
       "19  {'colsample_bytree': 0.9, 'subsample': 1.0}               14   \n",
       "20  {'colsample_bytree': 1.0, 'subsample': 0.6}               25   \n",
       "21  {'colsample_bytree': 1.0, 'subsample': 0.7}               20   \n",
       "22  {'colsample_bytree': 1.0, 'subsample': 0.8}                9   \n",
       "23  {'colsample_bytree': 1.0, 'subsample': 0.9}               16   \n",
       "24  {'colsample_bytree': 1.0, 'subsample': 1.0}                2   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.728044            0.848520           0.723493   \n",
       "1            0.728432            0.857340           0.724025   \n",
       "2            0.730111            0.850516           0.725108   \n",
       "3            0.725092            0.856241           0.726358   \n",
       "4            0.732711            0.845170           0.727408   \n",
       "5            0.726743            0.850237           0.724678   \n",
       "6            0.730176            0.858808           0.723253   \n",
       "7            0.727309            0.857096           0.724803   \n",
       "8            0.728450            0.860483           0.723956   \n",
       "9            0.728624            0.854176           0.728416   \n",
       "10           0.727337            0.855048           0.725502   \n",
       "11           0.724593            0.861012           0.720841   \n",
       "12           0.728976            0.867665           0.723487   \n",
       "13           0.730161            0.862143           0.728320   \n",
       "14           0.728445            0.859497           0.723611   \n",
       "15           0.722531            0.862634           0.723767   \n",
       "16           0.726882            0.869820           0.721203   \n",
       "17           0.728964            0.872582           0.724543   \n",
       "18           0.732686            0.870549           0.722363   \n",
       "19           0.730269            0.860869           0.723964   \n",
       "20           0.727150            0.860404           0.724117   \n",
       "21           0.728015            0.868499           0.725753   \n",
       "22           0.730922            0.865706           0.722846   \n",
       "23           0.728726            0.870146           0.725989   \n",
       "24           0.731673            0.860613           0.726544   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0             0.853176           0.723247            0.849355   \n",
       "1             0.859603           0.726137            0.856198   \n",
       "2             0.859639           0.722847            0.858763   \n",
       "3             0.859014           0.721512            0.858922   \n",
       "4             0.851675           0.722813            0.851245   \n",
       "5             0.856413           0.718104            0.854424   \n",
       "6             0.864128           0.720318            0.861290   \n",
       "7             0.861125           0.724414            0.862890   \n",
       "8             0.851510           0.721404            0.862825   \n",
       "9             0.857433           0.724867            0.854914   \n",
       "10            0.858190           0.722904            0.857257   \n",
       "11            0.864295           0.722251            0.865415   \n",
       "12            0.864542           0.723330            0.864733   \n",
       "13            0.870823           0.724370            0.869820   \n",
       "14            0.855728           0.722506            0.859698   \n",
       "15            0.858155           0.719495            0.862640   \n",
       "16            0.866742           0.721993            0.866260   \n",
       "17            0.870777           0.721044            0.869603   \n",
       "18            0.866344           0.719063            0.870877   \n",
       "19            0.865487           0.718622            0.861403   \n",
       "20            0.860056           0.717228            0.861734   \n",
       "21            0.866013           0.719965            0.868262   \n",
       "22            0.872601           0.720351            0.870552   \n",
       "23            0.870597           0.720358            0.868067   \n",
       "24            0.865417           0.722059            0.860335   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.722868            0.851548      1.194023        0.096704   \n",
       "1            0.722476            0.857057      1.423763        0.033147   \n",
       "2            0.722085            0.858084      1.251284        0.063795   \n",
       "3            0.723724            0.860359      1.544426        0.015179   \n",
       "4            0.721868            0.843527      0.220653        0.005594   \n",
       "5            0.723206            0.855710      0.350804        0.018858   \n",
       "6            0.724816            0.857216      1.761759        0.039023   \n",
       "7            0.721331            0.858772      0.262298        0.009668   \n",
       "8            0.728885            0.861686      0.162329        0.024495   \n",
       "9            0.721875            0.856548      1.358577        0.025205   \n",
       "10           0.720135            0.860314      5.329143        0.075669   \n",
       "11           0.724555            0.865565      1.627084        0.090704   \n",
       "12           0.726191            0.869143      1.032818        0.090470   \n",
       "13           0.724471            0.863887      2.715784        0.058173   \n",
       "14           0.724179            0.853700      0.293655        0.016950   \n",
       "15           0.725038            0.864149      6.159865        0.081660   \n",
       "16           0.722254            0.864796      0.184696        0.030209   \n",
       "17           0.723511            0.867261      0.649004        0.033006   \n",
       "18           0.721666            0.870186      7.069506        0.030270   \n",
       "19           0.724808            0.858550      0.297900        0.011200   \n",
       "20           0.722086            0.864453      0.432748        0.012715   \n",
       "21           0.721471            0.866922      0.302666        0.006465   \n",
       "22           0.725197            0.868526      0.328412        0.019227   \n",
       "23           0.722387            0.868929      3.308217        0.015051   \n",
       "24           0.725192            0.863398      0.227273        0.007287   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.002108         0.001830  \n",
       "1         0.002242         0.001258  \n",
       "2         0.003133         0.003642  \n",
       "3         0.001796         0.001494  \n",
       "4         0.004304         0.003606  \n",
       "5         0.003190         0.002395  \n",
       "6         0.003580         0.002615  \n",
       "7         0.002123         0.002211  \n",
       "8         0.003131         0.004475  \n",
       "9         0.002784         0.001289  \n",
       "10        0.002717         0.001891  \n",
       "11        0.001594         0.001834  \n",
       "12        0.002309         0.001956  \n",
       "13        0.002496         0.003722  \n",
       "14        0.002252         0.002546  \n",
       "15        0.002056         0.002245  \n",
       "16        0.002227         0.001829  \n",
       "17        0.002866         0.001931  \n",
       "18        0.005195         0.001832  \n",
       "19        0.004129         0.002499  \n",
       "20        0.003610         0.001729  \n",
       "21        0.003229         0.001012  \n",
       "22        0.003913         0.002548  \n",
       "23        0.003226         0.000998  \n",
       "24        0.003469         0.002095  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# now tune regularization\n",
    "parameters = {\n",
    " 'reg_alpha':[0, 1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42, learning_rate = 0.3, n_estimators = 100,\\\n",
    "                        max_depth = 7, min_child_weight = 1, n_jobs = -1,\\\n",
    "                        gamma = 0, colsample_bytree = 0.8, subsample = 0.9)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.273136</td>\n",
       "      <td>0.420562</td>\n",
       "      <td>0.726831</td>\n",
       "      <td>0.866668</td>\n",
       "      <td>0</td>\n",
       "      <td>{'reg_alpha': 0}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730161</td>\n",
       "      <td>0.862143</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>0.870823</td>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.724471</td>\n",
       "      <td>0.863887</td>\n",
       "      <td>1.728407</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.444616</td>\n",
       "      <td>0.403242</td>\n",
       "      <td>0.726831</td>\n",
       "      <td>0.866668</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'reg_alpha': 1e-05}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730161</td>\n",
       "      <td>0.862143</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>0.870823</td>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.724471</td>\n",
       "      <td>0.863887</td>\n",
       "      <td>0.686379</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.927022</td>\n",
       "      <td>0.523259</td>\n",
       "      <td>0.725391</td>\n",
       "      <td>0.866722</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'reg_alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.866058</td>\n",
       "      <td>0.724583</td>\n",
       "      <td>0.867367</td>\n",
       "      <td>0.721762</td>\n",
       "      <td>0.866272</td>\n",
       "      <td>0.726301</td>\n",
       "      <td>0.867192</td>\n",
       "      <td>1.438631</td>\n",
       "      <td>0.126639</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.811125</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.724738</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'reg_alpha': 0.1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.726777</td>\n",
       "      <td>0.868215</td>\n",
       "      <td>0.727051</td>\n",
       "      <td>0.867923</td>\n",
       "      <td>0.720369</td>\n",
       "      <td>0.870621</td>\n",
       "      <td>0.724755</td>\n",
       "      <td>0.864715</td>\n",
       "      <td>0.429789</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.520211</td>\n",
       "      <td>0.419725</td>\n",
       "      <td>0.725792</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>1</td>\n",
       "      <td>{'reg_alpha': 1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.868839</td>\n",
       "      <td>0.725824</td>\n",
       "      <td>0.874972</td>\n",
       "      <td>0.721705</td>\n",
       "      <td>0.871689</td>\n",
       "      <td>0.725466</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>2.040765</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.002474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.075361</td>\n",
       "      <td>0.253344</td>\n",
       "      <td>0.725410</td>\n",
       "      <td>0.741087</td>\n",
       "      <td>100</td>\n",
       "      <td>{'reg_alpha': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.730635</td>\n",
       "      <td>0.739353</td>\n",
       "      <td>0.724072</td>\n",
       "      <td>0.741196</td>\n",
       "      <td>0.722776</td>\n",
       "      <td>0.741929</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.741869</td>\n",
       "      <td>0.469993</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      30.273136         0.420562         0.726831          0.866668   \n",
       "1      26.444616         0.403242         0.726831          0.866668   \n",
       "2      31.927022         0.523259         0.725391          0.866722   \n",
       "3      30.811125         0.438099         0.724738          0.867869   \n",
       "4      29.520211         0.419725         0.725792          0.871148   \n",
       "5      19.075361         0.253344         0.725410          0.741087   \n",
       "\n",
       "  param_reg_alpha                params  rank_test_score  split0_test_score  \\\n",
       "0               0      {'reg_alpha': 0}                2           0.730161   \n",
       "1           1e-05  {'reg_alpha': 1e-05}                1           0.730161   \n",
       "2            0.01   {'reg_alpha': 0.01}                5           0.728916   \n",
       "3             0.1    {'reg_alpha': 0.1}                6           0.726777   \n",
       "4               1      {'reg_alpha': 1}                3           0.730175   \n",
       "5             100    {'reg_alpha': 100}                4           0.730635   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.862143           0.728320            0.870823   \n",
       "1            0.862143           0.728320            0.870823   \n",
       "2            0.866058           0.724583            0.867367   \n",
       "3            0.868215           0.727051            0.867923   \n",
       "4            0.868839           0.725824            0.874972   \n",
       "5            0.739353           0.724072            0.741196   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.724370            0.869820           0.724471   \n",
       "1           0.724370            0.869820           0.724471   \n",
       "2           0.721762            0.866272           0.726301   \n",
       "3           0.720369            0.870621           0.724755   \n",
       "4           0.721705            0.871689           0.725466   \n",
       "5           0.722776            0.741929           0.724157   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.863887      1.728407        0.017361        0.002496   \n",
       "1            0.863887      0.686379        0.011953        0.002496   \n",
       "2            0.867192      1.438631        0.126639        0.002602   \n",
       "3            0.864715      0.429789        0.004120        0.002674   \n",
       "4            0.869091      2.040765        0.017339        0.003001   \n",
       "5            0.741869      0.469993        0.005923        0.003066   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.003722  \n",
       "1         0.003722  \n",
       "2         0.000566  \n",
       "3         0.002100  \n",
       "4         0.002474  \n",
       "5         0.001042  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# tune the learning rate\n",
    "parameters = {\n",
    " 'learning_rate':[0.001, 0.01, 0.05, 0.1]\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42, n_estimators = 500,\\\n",
    "                        max_depth = 7, min_child_weight = 1, n_jobs = -1,\\\n",
    "                        gamma = 0, colsample_bytree = 0.8, subsample = 0.9,\\\n",
    "                        reg_alpha = 1e-5)\n",
    "clf = GridSearchCV(xgb_clf, parameters, cv = 4, scoring = 'roc_auc')\n",
    "clf.fit(X_xgb_train, y_xgb_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.233548</td>\n",
       "      <td>1.697775</td>\n",
       "      <td>0.724945</td>\n",
       "      <td>0.730845</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'learning_rate': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.725074</td>\n",
       "      <td>0.729771</td>\n",
       "      <td>0.729469</td>\n",
       "      <td>0.729398</td>\n",
       "      <td>0.722801</td>\n",
       "      <td>0.732032</td>\n",
       "      <td>0.722437</td>\n",
       "      <td>0.732180</td>\n",
       "      <td>10.832112</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162.736508</td>\n",
       "      <td>2.081786</td>\n",
       "      <td>0.727185</td>\n",
       "      <td>0.764619</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730010</td>\n",
       "      <td>0.765308</td>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.762186</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.764514</td>\n",
       "      <td>0.725036</td>\n",
       "      <td>0.766466</td>\n",
       "      <td>10.988058</td>\n",
       "      <td>0.173284</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.030479</td>\n",
       "      <td>2.145730</td>\n",
       "      <td>0.726918</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732961</td>\n",
       "      <td>0.880277</td>\n",
       "      <td>0.726596</td>\n",
       "      <td>0.878782</td>\n",
       "      <td>0.723646</td>\n",
       "      <td>0.883680</td>\n",
       "      <td>0.724468</td>\n",
       "      <td>0.880118</td>\n",
       "      <td>11.176660</td>\n",
       "      <td>0.180216</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.001808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.367225</td>\n",
       "      <td>2.070954</td>\n",
       "      <td>0.726077</td>\n",
       "      <td>0.925503</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.730410</td>\n",
       "      <td>0.924448</td>\n",
       "      <td>0.722752</td>\n",
       "      <td>0.925770</td>\n",
       "      <td>0.723807</td>\n",
       "      <td>0.927897</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>0.923896</td>\n",
       "      <td>11.533912</td>\n",
       "      <td>0.134065</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0     155.233548         1.697775         0.724945          0.730845   \n",
       "1     162.736508         2.081786         0.727185          0.764619   \n",
       "2     139.030479         2.145730         0.726918          0.880714   \n",
       "3     134.367225         2.070954         0.726077          0.925503   \n",
       "\n",
       "  param_learning_rate                    params  rank_test_score  \\\n",
       "0               0.001  {'learning_rate': 0.001}                4   \n",
       "1                0.01   {'learning_rate': 0.01}                1   \n",
       "2                0.05   {'learning_rate': 0.05}                2   \n",
       "3                 0.1    {'learning_rate': 0.1}                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.725074            0.729771           0.729469   \n",
       "1           0.730010            0.765308           0.728902   \n",
       "2           0.732961            0.880277           0.726596   \n",
       "3           0.730410            0.924448           0.722752   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            0.729398           0.722801            0.732032   \n",
       "1            0.762186           0.724793            0.764514   \n",
       "2            0.878782           0.723646            0.883680   \n",
       "3            0.925770           0.723807            0.927897   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.722437            0.732180     10.832112        0.115385   \n",
       "1           0.725036            0.766466     10.988058        0.173284   \n",
       "2           0.724468            0.880118     11.176660        0.180216   \n",
       "3           0.727338            0.923896     11.533912        0.134065   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.002801         0.001269  \n",
       "1        0.002306         0.001567  \n",
       "2        0.003651         0.001808  \n",
       "3        0.003024         0.001541  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=42, learning_rate = 0.01, n_estimators = 500,\\\n",
    "                        max_depth = 7, min_child_weight = 1, n_jobs = -1,\\\n",
    "                        gamma = 0, colsample_bytree = 0.8, subsample = 0.9,\\\n",
    "                        reg_alpha = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-cd766c8d02cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    501\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m                               verbose_eval=verbose)\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 886\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    887\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(X_xgb, y_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
